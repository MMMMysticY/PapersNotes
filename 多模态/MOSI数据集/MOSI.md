- [MOSI 一个在线视频中情感强度和主观性分析的多模态语料库](#mosi-一个在线视频中情感强度和主观性分析的多模态语料库)
  - [背景](#背景)
  - [挑战](#挑战)
  - [数据集内容](#数据集内容)
    - [采集方法](#采集方法)
    - [视频段分割](#视频段分割)
    - [情感强度标注](#情感强度标注)
    - [视觉姿势标注](#视觉姿势标注)
# MOSI 一个在线视频中情感强度和主观性分析的多模态语料库
## 背景
每天有超过300小时的视频上传到Youtube上，人们在视频相关的帖子或者评论区中发表观点，故事和评价。  
这些内容对于**opinion-mining**的应用来说，是很有效*作为总结任务，问答任务和视频检索分类任务等。  
## 挑战
1. 情感分析任务中，说话人经常在观点和主题之间切换，导致这些视频波动性很高，节奏很快，一句话可能表示了多个情感如：“他很好，但是我不想和他做生意。”，需要进行切分segment。
2. 同时，不是很容易去量化情感的强度和范围 因为不仅想要去分辨positive/negative 还需要分析情感的强度
3. 最大的挑战是如何使用不仅限于文本之外的信息 文本信息不一定能够确切地反应情感，如果加上视觉信息，是会有帮助的。如“这电影有点不一样”是不容易区分情感的，但是加上一个皱眉的图像是很有帮助的。

数据集对于挑战的解决：
1. 对于挑战1，其采用了十分细粒度的主观性的标签方法，用以在线视频的内容分割，即3702个视频，包括了2199个视点片段。
2. 对于挑战2，其采用了多个情绪的分级进行标注
3. 对于挑战3，其提出了与情感强度相关的语言和手势，进行多模态研究，进而提出了多模态字典multimodal dictionary的概念  
    同时，**采用了carefully synchronized 在文本和声音维度进行同步**

## 数据集内容
### 采集方法
从YouTube网站上获取的vlog 这类视频的好处是其一般只有一个说话人，并且大部分时间是看着镜头的  
视频的分布各不相同，有专业设备录制和简易设备录制的；有离得远的和离得近的；有背景光线好的和不好的  
视频大多2-5分钟，以mp4形式存储  
收集了93个视频，包括89个不同的语者，有41个女性和48个男性，大多数语者在20-30之间，所有演讲者都使用英语。  
将视频抽取为仅有语者说话的部分：
1. 人工进行抽取
2. 另一个人进行校准
3. 使用P2FA的强制对齐器aligner进行文字和音频的对齐
4. 再次校准

### 视频段分割
主观性分割的方法十分主观

### 情感强度标注
将情感标注为[-3, +3] 分别是  
1. strongly positive (+3)
2. positive (+2)
3. weakly  positive  (+1)
4. neutral  (0)
5. weakly negative (-1)
6. negative (-2)
7. strongly negative (-3)
8. uncertain表明不确定

### 视觉姿势标注
**音频和视频的feature自动从MPEG文件中抽取 音频是每秒1000? 视频时每秒30**  
**视频的特征包括：16个脸部动作单元，68个面部标记，头部动作和方向，6个基本情绪和视角**  
**音频特征包括：能量energy, pitch音调，NAQ归一化幅度商，MFCC梅尔频率倒谱系数，峰值斜率，能量斜率(COVAREP提取)**  